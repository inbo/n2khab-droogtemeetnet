---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Berekening droogte-indicator, betrouwbaarheid en trend {#h4:berekening}

We verkiezen een absolute indicator als droogte-indicator.
Bij een dergelijke indicator wordt het aantal dagen per jaar dat het grondwaterpeil gelijk aan of onder een kritische drempelwaarde zakt opgeteld.
Deze kritische drempelwaarde is specifiek voor elk meetpunt.
Als kritische drempelwaarde wordt gekozen voor 
**het _jaargemiddelde_ van de 5%-percentiel van de grondwatermetingen _van een jaar_ voor het meetpunt voor de periode 1985 - 2014**, cfr. \@ref(h3-2:drempelwaarde), die periodiek, bijv. elke vijftien jaar, met meer recente data kan herijkt worden, cfr. \@ref(h2-2-1:referentietoestand).

## Voorbereiding {#h4-1:voorbereiding}

Tot op heden kon met het software-programma Menyanthes voor 58 meetpunten een tijdreeksmodel gemaakt worden, waarbij 

- neerslag en potentiële evapotranspiratie voor minstens 66% van de waargenomen variatie kon verklaren en
- er geen significante trend in de tijdreeks kon gedetecteerd worden.

Met deze modellen werden 20 tijdreeksen van dagelijkse grondwaterpeilen gesimuleerd voor de periode 1985 - 2019.
Deze data werden in een centrale databank opgeslagen om daarna te worden ingelezen in R. 
De hierop volgende analysen gebeurden volledig in R.

```{r functies}
#grafiek voor het bekijken van de modelfitting. Het plot de gemeten data (in werkelijkheid omvatten ze zowel geïmputeerde data als veldmetingen) en de gefitte waarden incl credible interval. 

#hulpfunctie voor het maken van minor ticks in de grafieken
insert_minor <- function(major_labs, n_minor) {
  labs <- c( sapply( major_labs, function(x) c(x, rep("", 4) ) ) )
  labs[1:(length(labs) - n_minor)]}

#plot van de modelfitting
plotfitting <- function(indic_basis, respons, gemid, og, bg) {
  og <- enquo(og)
  bg <- enquo(bg)
  PI_data <- indic_basis %>% group_by(jaar) %>% 
    summarise(ymax_data = max(!! bg, na.rm = TRUE), ymin_data = min(!! og, na.rm = TRUE))
  p <- ggplot(data = indic_basis, aes_string(y = respons, x = "jaar"))
  p <- p + xlab("Jaar") + ylab(respons)
  p <- p + theme(text = element_text(size = 15))
  p <- p + geom_point(shape = 16, size = 2, col = "black")
  p <- p + geom_line(aes_string(x = "jaar", y = gemid), size = 1, color = "red")
  p <- p + geom_ribbon(data = PI_data,
                       aes(x = jaar, ymax = ymax_data, ymin = ymin_data), inherit.aes = F,
                       fill = grey(0.5),
                       alpha = 0.4)
  p <- p + scale_x_continuous(breaks = 1985:2020, 
                              labels = insert_minor(seq(1985, 2020, by = 5), 4))
  p <- p + theme(strip.text = element_text(size = 15))
  return(p)
}

#plot van de trend (zowel modelschatting als berekende)
plottrend <- function(indic_finaal, trend_berekend, intercept) {
  p <- ggplot(data = indic_finaal) + 
    geom_line(aes(x = jaar, y = og_jaar), linetype = "longdash") +
    geom_ribbon(aes(x = jaar, ymax = bg_jaar, ymin = og_jaar),
                fill = grey(0.5),
                alpha = 0.4) +  
    geom_line(aes(x = jaar, y = bg_jaar), linetype = "longdash") +
    geom_line(aes(x = jaar, y = gem_jaar), color = "dark blue") +
    geom_line(aes_string(x = "jaar", y = trend_berekend), color = "red") +
    # geom_point(data = indic_cum_basis, aes(x = jaar, y = lengte_onder_p01)) +
    geom_hline(aes(yintercept = intercept), linetype = "dotted") +
    scale_x_continuous(breaks = 1985:2020, labels = insert_minor(seq(1985, 2020, by = 5), 4)) +
    labs(x = "Jaar", y = "trend")
  return(p)
}

```


<!-- ### Inlezen van ruwe gegevens van de SQL-server {#h4-1-1:ruwedata} -->

```{r inlezen-ruwe-data-sqlserver, eval=FALSE}
# De ruwe data staan op de SQL-server in de FlaVen-databank.
# Het inlezen vergt een betrouwbare (langdurig werkzame) VPN-verbinding en vraagt ook veel tijd.
# Daarom werden de data na het inlezen omgezet in het VC-formaat en lokaal/in github bewaard.
# Het inlezen van deze bestanden gaat 3x-sneller dan het inlezen van de SQL-server.
# de brondata bestaat uit een reeks van 19 tabellen. Door deze op de SQL-server samen te voegen tot één bestand, zou het importeren falen.
# het rechtstreeks aanspreken van de SQL-server is een tijdrovend proces en het vraagt ook een stabiele verbinding, wat met een VPN-verbinding niet echt gegarandeerd is.
# Daarom werden de data na het inlezen lokaal weggeschreven in het vc-formaat mbv het git2rdata-package

con <- dbConnect(odbc::odbc(), .connection_string = "Driver=SQL Server;Server=inbo-sql07-prd.inbo.be,1433;Database=D0136_00_Flaven;Trusted_Connection=Yes;")



ruwetabellen_lijst <- data.frame (a = "droogte_tijdreeks", b = "ruwedata", c = seq(from = 1, to = 23))

ruwetabellen_lijst <- ruwetabellen_lijst %>% mutate (naambrontabel = paste0(a,c), 
                                                     naamdoeltabel = sprintf(paste0(b,"%02d"), c)) 

ruwetabellen_lijst <- setNames(ruwetabellen_lijst %>% dplyr::pull(naambrontabel), make.names(ruwetabellen_lijst %>% dplyr::pull(naamdoeltabel)))


list2env(
  lapply(ruwetabellen_lijst, 
         dbReadTable, conn = con,
         guess_max = 300000), 
  envir = .GlobalEnv)

DBI::dbDisconnect(con)


```

```{r wegschrijven-brontabellen-naar-vc-formaat, eval=FALSE }
for (i in seq(from = 1, to = 19)){
  write_vc(get(sprintf("ruwedata%02d", i)), file.path("data", "local", sprintf("ruwedata%02d", i)), sorting = c("dag","meetpunt_import"), strict= FALSE)
}

```


```{r inlezen-vc-tabellen, include=FALSE}
# De data worden niet in één keer ingelezen.
# De brondata zitten in 23 bestanden.
# Elk van deze 23 bestanden is op zich al vrij omvangrijk.
# Ze samenvoegen tot één bestand, zou kunnen leiden tot importproblemen.
# De opdeling is ook wel praktisch als je met de data iets wil testen.

ruwetabellen_lijst <- data.frame(bron = "ruwedata", doel = "ruwedata", c = seq(from = 1, to = 23))

ruwetabellen_lijst <- ruwetabellen_lijst %>% mutate (naambrontabel = file.path("data", "local", paste0(bron,sprintf("%02d", c))), 
                                                     naamdoeltabel = sprintf(paste0(doel,"%02d"), c)) 

ruwetabellen_lijst <- setNames(ruwetabellen_lijst %>% dplyr::pull(naambrontabel), make.names(ruwetabellen_lijst %>% dplyr::pull(naamdoeltabel)))

list2env(
  lapply(ruwetabellen_lijst, 
         read_vc), 
  envir = .GlobalEnv)

```

```{r samenvoegen-bestanden, include=FALSE}
#ik verkies dit in een aparte chunk te doen, omdat het zo mogelijk is om testdata samen te stellen, bijv. ik heb voor het uittesten van de methoden gewerkt met een testbestand van de eerste 5 ruwe tabellen.
for (i in seq (from = 1, to = 23)){
  if (i == 1) {
    ruwedata <- get(sprintf("ruwedata%02d",i))
  } else {
    ruwedata <- bind_rows(ruwedata, get(sprintf("ruwedata%02d",i)))
  }
}

#data cleaning - algemeen
# 1) uitsluiten van niet gesimuleerde meetreeksen (veldmetingen zitten namelijk al in de simuleerde reeksen, zou dus tot dubbeltellingen leiden) 
# 2) factoriseren van meetpunt en weglaten van ongebruikte velden 

ruwedata <-  ruwedata %>% 
  filter(meetpunt_import != meetreeks, year(dag) >= 1985) %>%  # 
  mutate(meetpunt = factor(meetpunt)) %>% 
  dplyr::select(-meetpunt_import, -meetreeks, -is_veldmeting) #om de grootte van het databestand te reduceren

#data-cleaning - specifiek voor de eerste dataset
#1) jaar 2019 is onvolledig: slechts data tot half mei

ruwedata <- ruwedata %>% 
  filter( year(dag) < 2019)
# indic_abs_basis_gw <- indic_abs_basis_gw %>% 
#   filter( between(simulatienr, 1,20), jaar < 2019)
```

```{r samenvoegen-bestanden-test, include=FALSE}
#ik verkies dit in een aparte chunk te doen, omdat het zo mogelijk is om testdata samen te stellen, bijv. ik heb voor het uittesten van de methoden gewerkt met een testbestand van de eerste 5 ruwe tabellen.
for (i in seq (from = 1, to = 5)){
  if (i == 1) {
    ruwetest <- get(sprintf("ruwedata%02d",i))
  } else {
    ruwetest <- bind_rows(ruwetest, get(sprintf("ruwedata%02d",i)))
  }
}

#data cleaning
ruwetest <-  ruwetest %>% 
  filter(meetpunt_import != meetreeks, year(dag) >= 1985) %>%  #uitsluiten van niet gesimuleerde meetreeksen (veldmetingen zitten namelijk al in de simuleerde reeksen, zou dus tot dubbeltellingen leiden)  
  mutate(meetpunt = factor(meetpunt)) %>% 
  dplyr::select(-meetpunt_import, -meetreeks, -is_veldmeting) #om de grootte van het databestand te reduceren

ruwetest <- ruwetest %>% 
  filter( year(dag) < 2019)
```

```{r verwijderen-tsv-tabellen, eval = FALSE}
#verwijderen van de 23 deelbestanden (beter nog niet doen als je wil testen, het is handig om te testen met één van de bestanden, bijv. ruwedata01 (rel. groot) of ruwedata19 (rel klein)
rm(list = sprintf("ruwedata%02d", seq(from = 1, to = 23)))

```

```{r tubes-network, include=FALSE}
#laatste versie met de geselecteerde meetpunten ophalen. De ruwe data bevatten namelijk ook nog meetreeksen van punten van een eerdere versie.
gitroot <- rprojroot::find_root(rprojroot::is_git_root)
tubes_selected <- read_vc(file.path(".","data","result","meetnet","tubes_selected"), root = gitroot)

tubes_indicator <- tubes_selected %>% 
  filter(selectie == 1) %>% 
  dplyr::select(loc_code, groupnr)

#beperken van de ruwe data tot de laatste versie van de geselecteerde meetpunten
ruwedata <- ruwedata %>% 
  semi_join(tubes_indicator, by = c("meetpunt" = "loc_code"))

# #linken van de metingen aan een gw-groep, cfr. MNM
# tubes_in_raster <- read_vc(file.path(".","data","processed","meetnet","tubes_in_raster"), root = gitroot)
# tubes_gw <- tubes_in_raster %>% 
#   dplyr::select(loc_code, groupnr)
# ruwedata <- ruwedata %>% 
#   left_join(tubes_gw, by = c("meetpunt" = "loc_code")) #left_join om te testen


```

### Berekenen kritische drempelwaarden {#h4-1-1:drempelwaarde}
Een absolute indicator vergelijkt dagelijks het grondwaterpeil met een kritische drempelwaarde. 
De dagen dat het grondwaterpeil onder deze drempelwaarde valt, worden per jaar opgeteld (\@ref(h3-2:drempelwaarde) en \@ref(h3-3:indicator)).

```{r absolute-drempelwaarden-schrikkeljaren, include=FALSE}
absperc <- ruwedata %>% 
  mutate(jaar = year(dag)) %>% 
  filter(dplyr::between(jaar,1985,2014)) %>% 
  group_by(meetpunt, jaar) %>% 
  summarise(p01 = quantile(meting_TAW, 1/100),
            p05 = quantile(meting_TAW, 5/100),
            p10 = quantile(meting_TAW, 10/100),
            p30 = quantile(meting_TAW, 30/100),
            p50 = quantile(meting_TAW, 50/100),
            p70 = quantile(meting_TAW, 70/100),
            p90 = quantile(meting_TAW, 90/100),
            p95 = quantile(meting_TAW, 95/100),
            p99 = quantile(meting_TAW, 99/100)
            ) %>% 
  group_by(meetpunt) %>% 
  summarise(p01 = mean(p01),
            p05 = mean(p05),
            p10 = mean(p10),
            p30 = mean(p30),
            p50 = mean(p50),
            p70 = mean(p70),
            p90 = mean(p90),
            p95 = mean(p95),
            p99 = mean(p99)
            ) %>%   
  ungroup()


schrikkeljaar <- ruwedata %>% 
  mutate(jaar = year(dag)) %>%   
  filter(meetpunt == 
           ruwedata %>% 
           dplyr::select(meetpunt) %>% 
           head(1) %>% 
           dplyr::pull(meetpunt)
         ) %>% 
  filter(day(dag) == 29, month(dag) == 2) %>% 
  distinct(jaar) %>% 
  arrange(jaar) %>% 
  dplyr::pull(jaar)


#vrijmaken geheugenruimte, kan soms van pas komen
  gc()
```
```{r gwgroups, include=FALSE}
#herijking grondwatertype-groepen, want er blijkt nog nauwelijks een verband te bestaan tussen de amplitude van een pb en de gw-typegroep waartoe het wordt gerekend
absperc_gw <- absperc %>% 
  inner_join(tubes_indicator %>% 
               mutate(groep3 = ifelse(groupnr == 1, 2, groupnr)) %>% 
               dplyr::select(-groupnr), by = c("meetpunt" = "loc_code")) %>% 
  mutate(ampl = p99 - p01,
         groep3n = case_when(
           ampl < 0.25 ~2,
           ampl < 0.4 ~3,
           TRUE ~4),
         meetpunt = factor(meetpunt)
         )

write_vc(absperc_gw, file.path("data", "result", "percentielen_1985_2014"), sorting = c("meetpunt"), strict = FALSE)
```

```{r abs-indicator}

dagen_droog <- ruwedata %>% #oude objectnaam: indic_abs_basis
  inner_join(absperc_gw, by = "meetpunt") %>% 
  mutate(jaar = year(dag),
         aantaldagen_jaar = if_else(jaar %in% schrikkeljaar, 366, 365 )
         ) %>% 
  mutate( 
          dag_onder_p01 = if_else(meting_TAW < p01,1,0),
          dag_onder_p05 = if_else(meting_TAW < p05,1,0),
          dag_onder_p10 = if_else(meting_TAW < p10,1,0),
          dag_onder_p30 = if_else(meting_TAW < p30,1,0),
          dag_boven_p01 = if_else(dag_onder_p01 == 0,1,0),
          dag_boven_p05 = if_else(dag_onder_p05 == 0,1,0),
          dag_boven_p10 = if_else(dag_onder_p10 == 0,1,0),
          dag_boven_p30 = if_else(dag_onder_p30 == 0,1,0)          
  ) %>% 
  group_by(meetpunt, simulatienr,jaar, aantaldagen_jaar, groep3, groep3n) %>% 
  summarise_at(vars(dag_onder_p01:dag_boven_p30), sum) %>% 
  ungroup() %>% 
  mutate(jaar_factor = factor(jaar)
  )

# #met opgave gw-groep
# indic_abs_basis_gw <- ruwedata %>% 
#   inner_join(absperc_gw, by = "meetpunt") %>% 
#   mutate(jaar = year(dag),
#          meetpunt = factor(meetpunt),
#          aantaldagen_jaar = if_else(jaar %in% schrikkeljaar, 366, 365 )
#   ) %>% 
#   mutate( 
#     dag_onder_p01 = if_else(meting_TAW < p01,1,0),
#     dag_onder_p05 = if_else(meting_TAW < p05,1,0),
#     dag_onder_p10 = if_else(meting_TAW < p10,1,0),
#     dag_onder_p30 = if_else(meting_TAW < p30,1,0),
#     dag_boven_p01 = if_else(dag_onder_p01 == 0,1,0),
#     dag_boven_p05 = if_else(dag_onder_p05 == 0,1,0),
#     dag_boven_p10 = if_else(dag_onder_p10 == 0,1,0),
#     dag_boven_p30 = if_else(dag_onder_p30 == 0,1,0)          
#   ) %>% 
#   group_by(groep3n, meetpunt, simulatienr,jaar, aantaldagen_jaar) %>% 
#   summarise_at(vars(dag_onder_p01:dag_boven_p30), sum) %>% 
#   ungroup() %>% 
#   mutate(jaar_factor = factor(jaar)
#   )


```
### Verdeling van de indicator {#h4-1-2:verdeling-indicator}

De techniek die we wensen toe te passen bij de modelbouw is parametrisch: ze vereist dat er assumpties gemaakt worden over de verdeling van de afhankelijke variabele.

We beschikken voor elk jaar en meetpunt over twintig simulaties.
Dit laat in zekere mate toe de verdeling ervan te bestuderen.

In theorie is de indicator te beschouwen als een discrete variabele. 
Het feit dat er een kritische drempelwaarde is die al dan niet overschreden wordt en het aantal dagen van een jaar (= aantal 'pogingen') vast ligt, wijzen in de richting van een binomiale verdeling met n = 365 of 366 en p = 0.05.

De p-waarde ligt echter niet vast.
De kritische drempelwaarde werd immers bepaald op basis van een gemiddelde over 30 jaar. 
In droge jaren zal de kans p dat deze zal overschreden worden, veel groter zijn dan in natte jaren.
In dat geval is een negatief binominale verdeling meer aangewezen.

Een groter probleem is dat één belangrijke conditie voor een verdeling wordt geschonden. 
De 'trekkingen' gebeuren namelijk niet onafhankelijk van elkaar: de kans dat als het vandaag een droge dag is, het dat morgen of overmorgen ook zal zijn is veel groter dan 0.05 en vice versa. 

Daarom werd de verdeling van de indicator niet alleen vergeleken met de negatief-binominale, maar ook met de poisson- en de binominale verdeling. 

Voor deze vergelijking werd gebruikt gemaakt van zogenaamde QQ-plots. 
Een QQ-plot zet de kans uit dat een bepaalde waarde of kleiner uit een bepaalde verdeling wordt getrokken uit ten opzichte van de percentielwaarde van deze waarde.

De verdelingen werden steekproefgewijs getest op een aantal meetpunten en jaren. 
Deze testen gaven aan dat de verdeling vrij goed overeenkwam met de binomiale of negatief binomiale verdeling. 
De overeenkomst met de poisson-verdeling was meestal relatief iets minder goed.

```{r check-distribution-qq}

checkdistributie <- dagen_droog %>% 
                                 filter(jaar == 2006, meetpunt == "ASBP003") %>% #ALMP003 ASBP003 BTRP001 COOP001 DYLP029 GSCP017
        dplyr::pull(dag_onder_p05)

```

De figuren \@ref(fig:check-qq-poisson), \@ref(fig:check-qq-nbinom) en \@ref(fig:check-distribution-qq-binom) geven een voorbeeld van een QQ-plot voor resp. de poisson, de negatief-binomiale en binomiale verdeling.

```{r check-qq-poisson, fig.cap = "QQ-plot poisson-verdeling"}

poisson <- MASS::fitdistr(checkdistributie, "Poisson")
car::qqp(checkdistributie, "pois", lambda = poisson$estimate, id = FALSE)

```

```{r check-qq-nbinom, fig.cap = "QQ-plot negatief binomiale-verdeling"}

nbinom <- MASS::fitdistr(checkdistributie, "Negative Binomial")
qqPlot(checkdistributie, "nbinom", size = nbinom$estimate[[1]], mu = nbinom$estimate[[2]], id = FALSE)

```

```{r check-distribution-qq-binom, fig.cap = "QQ-plot binomiale-verdeling"}
binom <- fitdistrplus::fitdist(checkdistributie, "binom", fix.arg = list(size = 365), start = list(prob = 0.1))
#summary(binom)
qqp(checkdistributie, "binom", size = 365, prob = binom$estimate, id = FALSE)

```


```{r check-distribution boxplot, eval = FALSE}
boxplot(checkdistributie/365)

#ggplot(data = checkdistributie, aes(dag_onder_p01)) + geom_histogram() 
#ggplot(data = data.frame(checkdistributie), aes(dag_onder_p05)) + geom_histogram() 
#ggplot(data = checkdistributie, aes(dag_onder_p10)) + geom_histogram()  
#ggplot(data = checkdistributie, aes(dag_onder_p30)) + geom_histogram()
```


```{r}
check <- dagen_droog %>% 
  group_by(meetpunt) %>% 
  count()
```

## Berekening van de droogte-indicator en haar betrouwbaarheid {#h4-2:droogte-indicator}

### Droogte-indicator {#h4-2-1:droogte-indicator}
De droogte-indicator is op zich vrij eenvoudig te berekenen door voor elk jaar het gemiddelde te berekenen van de ${\text {dagen_droog}}$-waarden, cfr. \@ref(h3-3:indicator).


Tabel \@ref(fig:droogte-indicator) geeft de berekende indicator-waarden.


```{r droogte-indicator, include = TRUE, fig.cap="Droogte-indicator 1985 - 2018"}
droogte_ind_j <- dagen_droog %>% 
  group_by(jaar) %>% 
  summarise(droogte_ind_j = mean(dag_onder_p05)
            ) %>% 
  ungroup()

DT::datatable(
  droogte_ind_j %>% 
    rename (indicator = droogte_ind_j),
  caption = "Droogte-indicator 1985 - 2018",
  width = 600
  ) %>% 
  DT::formatRound(columns = 2,
                  digits = 1)

```


Figuur \@ref(fig:droogte-indicator-figuur) is hiervan een grafische weergave.
De groene lijn in de figuur geeft het aantal dagen dat jaarlijks gemiddeld verwacht wordt.
Voor een toelichting van de figuur zie verder (\@ref(h4-2-2:betrouwbaarheid)).

```{r droogte-indicator-figuur, fig.cap= "Droogte-indicator 1985 - 2018"}
g <- ggplot(data = droogte_ind_j, aes(x = jaar, y = droogte_ind_j)) + 
  geom_area() + theme_inbo() +
  geom_point(color = "red", shape = "cross") +
  geom_hline(yintercept = 365*0.05, color = "green", linetype = "dashed") +
  labs (y = "aantal droge dagen") + 
  scale_x_continuous(n.breaks = nrow(droogte_ind_j)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
g
```
### Betrouwbaarheid {#h4-2-2:betrouwbaarheid}

We wensen ook inzicht te krijgen in de onzekerheid die er op de droogte-indicator zit, m.a.w. wat is het betrouwbaarheidsinterval van de droogte-indicator.
We doen hiervoor beroep op de formule van Rubin (\@ref(h3-3:indicator)). 
Deze formule laat toe de onzekerheid die inherent is aan de data (verschillen tussen de locaties) te scheiden van de onzekerheid door het ontbreken van gegevens.

```{r droogte-indicator-met-ci, include=FALSE}
droogte_ind_j_s <- dagen_droog %>% 
  group_by(jaar, simulatienr) %>% 
  summarise(droogte_ind_j_s = mean(dag_onder_p05),
            aantal = n(),
            dagen_droog_se = sd(dag_onder_p05)/sqrt(aantal)
            ) %>% 
  ungroup()

droogte_ind_j_var <- droogte_ind_j_s %>% 
  inner_join(droogte_ind_j) %>% 
  group_by(jaar) %>% 
  summarise(dagen_droog_gem_var = mean(dagen_droog_se^2),
            aantalsim= n(),
            imput_var = (1+1/aantalsim) * sum((droogte_ind_j_s - droogte_ind_j)^2/(aantalsim-1)),
            droogte_ind_j_var = dagen_droog_gem_var + imput_var
            ) %>% 
  ungroup() %>% 
  dplyr::select (-aantalsim)

droogte_ind_j_var <- droogte_ind_j_var %>% 
  mutate (rel_bijdrage_imput = round(imput_var/droogte_ind_j_var*100,0))


droogte_ind_j <- droogte_ind_j %>% 
  inner_join(droogte_ind_j_var %>% 
               dplyr::select(-starts_with(c("dagen", "imput", "rel")))) %>% 
  mutate(lcl = droogte_ind_j - 1.96*sqrt(droogte_ind_j_var),
         ucl = droogte_ind_j + 1.96*sqrt(droogte_ind_j_var)
         )

```

```{r droogte-indicator-met-ci-vc, include=FALSE}
write_vc(droogte_ind_j, file.path("data", "result", "droogte-indicator"), sorting = c("jaar"), strict= FALSE)
```

Tabel \@ref(fig:droogte-indicator-ci-tbl) geeft de berekende indicator-waarden inclusief het 95% betrouwbaarheidsinterval (CI).

```{r droogte-indicator-ci-tbl, include = TRUE, fig.cap="Droogte-indicator inclusief 95% betrouwhaarheidsinterval 1985 - 2018"}

DT::datatable(
  droogte_ind_j %>% 
    dplyr::select(-droogte_ind_j_var) %>% 
    rename ('ondergrens (95% CI)' = lcl,
            'bovengrens (95% CI)' = ucl,
            indicator = droogte_ind_j
            ),
  caption = "Droogte-indicator inclusief 95% betrouwhaarheidsinterval (CI) 1985 - 2018"
  ) %>% 
  DT::formatRound(columns = 2:4,
                  digits = 1)

```



Figuur \@ref(fig:droogte-indicator-met-ci-figuur) is hiervan een grafische weergave.
De groene lijn in de figuur geeft het aantal dagen dat jaarlijks gemiddeld verwacht wordt.

Het grillige patroon van de indicator springt hierbij in het oog.
Een 'normaal' jaar is eerder uitzondering dan regel.
Als het droog is, is het ook vaak flink droog. 
Natte jaren zijn minder opvallend, omdat de droogte-indicator niet onder nul kan gaan.
Uitgezonderd voor het jaar 2018 zit er vrij weinig variatie in de hoogte van de pieken. 
Men ziet wel een wijziging in de frequentie ervan, met een toename vanaf rond 2000.
Dit wordt verder onderzocht in het onderzoek van de trend.

```{r droogte-indicator-met-ci-figuur, fig.cap= "Droogte-indicator"}
g <- ggplot(data = droogte_ind_j, aes(x = jaar, y = droogte_ind_j)) + 
  theme_inbo() +
  geom_ribbon(aes(ymin = lcl, ymax = ucl)) +
  geom_hline(yintercept = 365*0.05, color = "green", linetype = "dashed") +
  geom_line(color = "red", size = 0.5) + 
  labs (y = "droogte-indicator") + 
  scale_x_continuous(n.breaks = nrow(droogte_ind_j)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
g
```

De formule van Rubin laat toe om in te schatten wat de kost is van het ontbreken van data op de betrouwbaarheid van het resultaat.
Onderstaande figuur (\@ref(fig:droogte-indicator-imput-fig)) toont het aandeel in de totale variatie ten gevolge van het schatten van ontbrekende gegevens. 
Dit is meestal meer dan 10% en kan tot 50% bedragen.
Er zit een duidelijke neerwaartse trend in.
Deze trend is te verklaren door de toegenomen meetintensiteit.

```{r droogte-indicator-imput-fig, fig.cap="het aandeel van imputatie in de totale variatie", message=FALSE}
g <- ggplot(data = droogte_ind_j_var, aes(x = jaar, y= rel_bijdrage_imput)) + 
  geom_line() + geom_smooth() + theme_inbo() +
  labs (y = "aandeel (%)") + 
  scale_x_continuous(n.breaks = nrow(droogte_ind_j)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
g
```

## Berekening van de trend in de droogte-indicator {#h4-3:trend}

Bij een indicator is het verloop van de waarden nog belangrijker dan de absolute waarden an sich.
Zijn in onze de natuurgebieden de grondwaterpeilen ten gevolge van neerslagtekort aan het dalen ?
Om dit te kunnen nagaan stellen we een model op dat de variatie in de indicatorwaarden tracht te verklaren. 
In het model is de factor tijd één van de verklarende variabelen.
De andere verklarende factor is de locatie (de ene plaats kan een afwijkend gedrag vertonen dan een andere).
We onderzoeken hier alleen het tijdsaspect. 
Een mogelijke andere interessante vraag is of er regionale verschillen zijn tussen de waarden en waardoor deze dan  kunnen verklaard worden. 
Deze vragen blijven momenteel nog onbeantwoord.

Voor de berekening van de trend doen we beroep op Bayesiaanse modeltechnieken.
Deze technieken laten toe om voorkennis over de data te gebruiken bij het modelleren. 
We passen dit principe toe bij de vorm van de curve die we aan de trendlijn willen geven.
Een model dat heel goed de data kan voorspellen zal ongeveer het grillige patroon volgen van de indicator. 
We hebben dan wel een heel goed model, alleen bekomen we zo weinig extra informatie of er nu een geleidelijke verandering aan de gang is.
Door uit te gaan of op te leggen dat de curve elk jaar niet veel mag veranderen, kunnen we de curve minder grillig laten zijn. 

Het instellen van deze 'smoothing' = het meer of minder grillig laten zijn van de trendlijn is een subjectief gegeven en steunt ook op trial en error van de keuze van de smoothing-parameters.  
De trendlijn is daarom te interpreteren als 'stel dat de toe- of afname (min of meer) rechtlijnig zou zijn, hoe zou die trendlijn er dan uitzien'.

```{r abs-indic-model-function-exploratory, eval=FALSE}
indic_abs_function <- function(modeldata, suffix= "", respons, percentile, indicatorname, standardised) {

  #instellen van de priors. Dit is 
  #prec.prior <- list(prec = list(param = c(0.001, 0.001)))
  
  #De instelling van de prior heeft een doorslaggevend effect op de vorm van de trendlijn. 
  #Geven we het model de vrijheid om een trendlijn te bepalen dan voegen we weinig apriori-kennis toe aan het model
  #Voor de random-walk van de tweede orde doen we dat via de prior voor de precisie. Deze bevat twee elementen: de standaarddeviatie en een alfa. Het eerste element geeft aan in welke mate we denken/willen dat de rw2 mag fluctueren en en de alfa de zekerheid die we daarover hebben. Wil je een quasi rechte lijn, dan moeten beide parameters klein ingesteld worden. Laat je ze vrij, dan kan de trend een grillig patroon gaan vertonen.
  prec.prior <- list(theta = list(prior = "pc.prec", param = c(0.025, 0.001)))# list(theta = list(prec = list(param = c(0.001, 0.001))))  
  # prec.prior <- list(theta = list(prior = "pc.prec", param = c(0.25, 0.001)))# list(theta = list(prec = list(param = c(0.001, 0.001))))  
  # prec.prior <- list(theta = list(prior = "pc.prec", param = c(0.25, 0.95)))# list(theta = list(prec = list(param = c(0.001, 0.001))))  
  # prec.prior <- list(theta = list(prior = "pc.prec", param = c(2.5, 0.95)))# list(theta = list(prec = list(param = c(0.001, 0.001))))  
  # prec.prior <- list(theta = list(prior = "pc.prec", param = c(2.5, 0.001)))# list(theta = list(prec = list(param = c(0.001, 0.001))))  
  # prec.prior <- list(theta = list(prior = "pc.prec", param = c(0.0025, 0.001)))# list(theta = list(prec = list(param = c(0.001, 0.001))))  
  # prec.prior <- list(theta = list(prior = "pc.prec", param = c(0.0025, 0.99)))# list(theta = list(prec = list(param = c(0.001, 0.001))))  
  # prec.prior <- list(theta = list(prior = "pc.prec", param = c(0.0025, 0.0001)))# list(theta = list(prec = list(param = c(0.001, 0.001))))  
  prec.prior.mp <- list(theta = list(prior = "pc.prec", param = c(0.025, 0.95)))# list(theta = list(prec = list(param = c(0.001, 0.001)))) 
  model <- as.formula(paste(respons, "~", "f(jaar, model =", "'rw2', scale.model = TRUE,
                          hyper = prec.prior)+ f(meetpunt, model = 'iid', hyper = prec.prior.mp)", sep = " "))   
  # model <- as.formula(paste(respons, "~", "1 + jaar_factor + f(meetpunt, model = 'iid', hyper = prec.prior)", sep = " "))     
  suffix <- ifelse(suffix == "", "", paste0("_", suffix))
  resultname_stat <- paste0("indic_abs_p", percentile, suffix, "_jaar_stat", if (standardised == TRUE) ("_std"))
  resultname_fitted <- paste0("indic_abs_p", percentile, suffix, "_fitted", if (standardised == TRUE) ("_std"))
  if (percentile == "01") {
    reeks <- c(1:20) #1 model wou maar niet convergeren
  } else {
    reeks <- c(1:20)    
  }  
  teller <- 0
  for (i in reeks) {
    #i = 16
    mdata <- modeldata[modeldata$simulatienr == i,]
    jaren <- mdata %>% distinct(jaar) %>% mutate(simulatienr = i)
    
    #samenstellen van een tweeledig dataframe. De eerste 34 rijen (#jaren) zijn leeg en dienen om de gemiddelde waarden en de bijhorende fouten te berekenen. Het tweede deel dient om het model mee te bouwen
    mdata <- bind_rows(jaren, mdata)    
    # mdata[mdata[,respons] == 0,respons] <- 1e16
    print(i)    
    teller <- teller + 1
    I2 <- inla(model, 
                     control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
                     family = modelkeuze %>% filter(percentiel == percentile) %>% 
                              dplyr::pull(model), 
                     #Ntrials = aantaldagen_jaar,
                     data = mdata
    )

    # I2b <- inla(model,
    #            control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
    #            family = "nbinomial",
    #            #Ntrials = aantaldagen_jaar,
    #            data = mdata
    # )
    # I2c <- inla(model,
    #             control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
    #             family = "zeroinflatednbinomial1",
    #             #Ntrials = aantaldagen_jaar,
    #             data = mdata,
    #             verbose = FALSE
    # )
    # I2d <- inla(model,
    #             control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
    #             family = "zeroinflatednbinomial0",
    #             #Ntrials = aantaldagen_jaar,
    #             data = mdata
    # )
    # de negatieve binomiale modellen gebruiken de logit-link
    #om de niet-getransformeerde waarden te krijgen moet men zowel de intercept als de coëfficiënten exponentiëren. Exp(standaardfout) heeft geen zin, maar het was moeilijker om deze uit te sluiten dan ze (verkeerdelijk) mee te nemen
    #summary(I2)
    # result_stat_i <-  I2$summary.random$jaar %>%
    #   mutate_at(names(I2$summary.random$jaar)[2:6], exp) %>%
    #   mutate_at(names(I2$summary.random$jaar)[2:6], function(x){x*exp(I2$summary.fixed$mean)}) %>%       mutate(simulatienr = i) %>%
    #   dplyr::select(-sd, -mode, -kld)
    
    #linear_predictor : deze is niet teruggetransformeteerd. We zijn hier alleen geïnteresseerd in de rijen met lege responsen: hier krijg je dan per jaar een gemiddelde predictie én de se.
    result_stat_i <- I2$summary.linear.predictor %>% 
      slice(1:nrow(jaren)) %>% 
      bind_cols(jaren) %>% 
      mutate(intercept = I2$summary.fixed$mean) %>% 
      dplyr::select(-mode, -kld)    
    #summary(I2b)  
    #modelkeuze %>% filter(percentiel == percentile) %>% dplyr::pull(model)

    # sum(log(I2$cpo$cpo))
    # sum(log(I2b$cpo$cpo))
    # sum(log(I2c$cpo$cpo))
    # sum(log(I2d$cpo$cpo))
    # # sum(log(I2_binom$cpo$cpo))
    # 
    # sum(log(I2$dic$dic))
    # sum(log(I2b$dic$dic))
    # sum(log(I2c$dic$dic))
    # sum(log(I2d$dic$dic))
    # 
    # sum(log(I2$waic$waic))
    # sum(log(I2b$waic$waic))
    # sum(log(I2c$waic$waic))
    # sum(log(I2d$waic$waic))
    # 
    # sum(I2$mlik)
    # sum(I2b$mlik)
    # sum(I2c$mlik)
    # sum(I2d$mlik)

    # names(inla.models()$likelihood)
    
    # # Assess overdispersion (variantie / aantal vrijheidsgraden ~ 1)
     # #voor binomiaal
     # Pi   <- I2b$summary.fitted.values[,"mean"]
     # ExpY <- Pi * mdata$aantaldagen_jaar
     # VarY <- Pi * mdata$aantaldagen_jaar * (1 - Pi)
     # E1   <- (mdata %>%
     #               dplyr::pull(!!indicatorname) - ExpY) / sqrt(VarY)
     # N    <- nrow(mdata)
     # p <- nrow(I2b$summary.fixed)
     # Dispersion <- sum(E1^2) / (N - p)
     # Dispersion
    
    # #voor poisson
    # Pi   <- I2c$summary.fitted.values[,"mean"]
    # ExpY <- Pi #* mdata$aantaldagen_jaar
    # VarY <- Pi #* mdata$aantaldagen_jaar * (1 - Pi)
    # E1   <- (mdata %>%
    #               dplyr::pull(!!indicatorname) - Pi) / sqrt(VarY)
    # N    <- nrow(mdata)
    # p <- nrow(I2c$summary.fixed)
    # Dispersion <- sum(E1^2) / (N - p)
    # Dispersion
    
    # #voor negatief binomiaal
    # Pi  <- I2$summary.fitted.values[,"mean"] [-(1:nrow(jaren))]
    # theta <- I2$summary.hyperpar[1,"mean"]
    # E1 <- (mdata %>% slice(-(1:nrow(jaren))) %>%
    #          dplyr::pull(!!indicatorname)  - Pi) / sqrt(Pi + Pi^2 / theta)
    # sum(E1^2) / (nrow(mdata) - 1)
    # 
    # Pi  <- I2b$summary.fitted.values[,"mean"]
    # theta <- I2b$summary.hyperpar[1,"mean"]
    # E1 <- (mdata %>% slice(-(1:nrow(jaren))) %>%
    #          dplyr::pull(!!indicatorname)  - Pi) / sqrt(Pi + Pi^2 / theta)
    # sum(E1^2) / (nrow(mdata) - 1)


    # 
    # Pi  <- I2c$summary.fitted.values[,"mean"]
    # theta <- I2c$summary.hyperpar[1,"mean"]
    # E1 <- (mdata %>%
    #          dplyr::pull(!!indicatorname)  - Pi) / sqrt(Pi + Pi^2 / theta)
    # sum(E1^2) / (nrow(mdata) - 1)
    # 
    # 
    # Pi  <- I2d$summary.fitted.values[,"mean"]
    # theta <- I2d$summary.hyperpar[1,"mean"]
    # E1 <- (mdata %>%
    #          dplyr::pull(!!indicatorname)  - Pi) / sqrt(Pi + Pi^2 / theta)
    # sum(E1^2) / (nrow(mdata) - 1)
    # 
    # # Pearson residuals
    # par(mfrow = c(1,1), mar = c(5,5,2,2), cex.lab = 1.5)
    # plot(x = Pi,
    #      y = E1,
    #      xlab = "Fitted values",
    #      ylab = "Pearson residuals")
    # abline(h = 0, lty = 2)
    # 
    # #names(inla.models()$likelihood)
    # 
    # # bekijk de gefitte waarden van het model
    # # Plot the fitted values
    # Fit1     <- I2$summary.fitted.values[,"mean"][-(1:nrow(jaren))]
    # Fit1.025 <- I2$summary.fitted.values$"0.025quant"[-(1:nrow(jaren))]
    # Fit1.975 <- I2$summary.fitted.values$"0.975quant"[-(1:nrow(jaren))]
    # # 
    # # Fit1     <- I2d$summary.fitted.values[,"mean"]
    # # Fit1.025 <- I2d$summary.fitted.values$"0.025quant"
    # # Fit1.975 <- I2d$summary.fitted.values$"0.975quant"
    # # 
    # check <- I2$summary.fitted.values[,"mean"][(1:nrow(jaren))] %>% bind_cols(jaren)
    # check2 <- mdata2 %>%
    #   group_by(jaar) %>%
    #   summarise(gemj = mean(Fitted1))
    # check <- check %>% inner_join(check2, by = "jaar")
    # write_csv(check, "check.csv")
    # result_stat_i2 <- result_stat_i2 %>%
    #   mutate(terug = inla.link.log(mean, inverse = TRUE))
    # #   #
    # # check <- I2$summary.random$meetpunt
    # #
    # # result_fitted_i
    # mdata2 <- mdata %>% slice(-(1:nrow(jaren)))
    # mdata2$Fitted1  <- Fit1
    # mdata2$Fit1.025 <- Fit1.025
    # mdata2$Fit1.975 <- Fit1.975
    # #gdata <- mdata %>% dplyr::select(!!respons, jaar, contains("Fit"))
    # p <- ggplot(data = mdata2, aes_string(y = respons, x = "jaar"))
    # p <- p + xlab("Jaar") + ylab(respons)
    # p <- p + theme(text = element_text(size = 15))
    # p <- p + geom_point(shape = 16, size = 2, col = "black")
    # p <- p + geom_line(aes(x = jaar, y = Fitted1))
    # p <- p + geom_ribbon(data = mdata2 %>% group_by(jaar) %>% summarise(ymax_data = max(Fit1.975), ymin_data = min(Fit1.025)), aes(x = jaar,
    #                          ymax = ymax_data,
    #                          ymin = ymin_data), inherit.aes = F,
    #                      fill = grey(0.5),
    #                      alpha = 0.4)
    # p <- p + theme(strip.text = element_text(size = 15))
    # p
    # summary(I2)
    # result_stat_i <-  I2$summary.random$jaar %>%
    #   mutate(simulatienr = i)
    #  result_stat_i <- result_stat_i %>%  rename (p0.025 = '0.025quant',
    #                              p975.5 = '0.975quant',
    #                              jaar =  ID)
    #  gplot <- ggplot(data = result_stat_i, aes(x = jaar, y = mean)) +
    #    geom_line(aes(x = jaar, y = p0.025), linetype = "longdash") +
    #    geom_ribbon(aes(x = jaar, ymax = p975.5, ymin = p0.025)) +
    #    geom_line(aes(x = jaar, y = p975.5), linetype = "longdash") +
    #    geom_line(color = "lightblue") +
    #    #geom_point(data = mdata, aes_string(x = "jaar", y = respons)) +
    #    geom_hline(aes(yintercept = 0), linetype = "dotted") +
    #    labs(x = "Jaar", y = "trend")
    #  gplot
    # 
    # #conclusie negative binomiaal (bij 30 wel onderdispersed), gestandardiseerd met een gewijzigde non-informatieve prior
    # 
    # result_stat_i_meetpunt <-  I2$summary.random$meetpunt %>% 
    #   mutate(simulatienr = i)
    
    # result_stat_i <- result_stat_i %>% 
    #   mutate(og_berekend = mean - 1.96*sd,
    #          bg_berekend = mean + 1.96*sd)
    
    #gefitte waarden (deze zijn wel teruggetransformeteerd)    
    varname_mean <- paste0("p", percentile, "_mean", if (standardised == TRUE) ("_std"), "_fitted")
    varname_sd <- paste0("p", percentile, "_sd", if (standardised == TRUE) ("_std"), "_fitted")
    varname_p025 <- paste0("p", percentile, "_p02.5", if (standardised == TRUE) ("_std"), "_fitted")
    varname_p975 <- paste0("p", percentile, "_p97.5", if (standardised == TRUE) ("_std"), "_fitted")
    result_fitted_i <-  I2$summary.fitted.values %>% 
      rename(!!varname_mean := mean,
             !!varname_sd := sd,
             !!varname_p025 := '0.025quant',
             !!varname_p975 := '0.975quant')

    mdata <- bind_cols(mdata, result_fitted_i) %>% 
      slice(-(1:nrow(jaren))) #de regels met lege responsen hieruit verwijderen    
    if (standardised == TRUE) {
      varname_mean_backtransformed <- paste0(varname_mean, "_untr")
      varname_p025_backtransformed <- paste0(varname_p025, "_untr")
      varname_p975_backtransformed <- paste0(varname_p975, "_untr")
      result_fitted_i <- result_fitted_i %>% 
        mutate( !!varname_mean_backtransformed := unscale(result_fitted_i %>% 
                                                            dplyr::pull(!!varname_mean),m,s),
                !!varname_p025_backtransformed := unscale(result_fitted_i %>% 
                                                            dplyr::pull(!!varname_p025),m,s),
                !!varname_p975_backtransformed := unscale(result_fitted_i %>% 
                                                            dplyr::pull(!!varname_p975),m,s)    
        )
    }
    if (teller == 1) {
      result_stat <- result_stat_i
      result_fitted <- mdata
      
    } else {
      result_stat <- bind_rows(result_stat, 
                               result_stat_i)
      result_fitted <- bind_rows(result_fitted, mdata)    
    }
    
    if (teller == length(reeks)) {  
      result_stat <- result_stat %>% 
        rename( p02.5 = '0.025quant',
                p50 = '0.5quant',
                p97.5 = '0.975quant')
      
        if (standardised == TRUE) {
          result_stat <- result_stat %>% 
            mutate(mean_untr = unscale(mean, m, s),
                   og_berekend_untr = unscale(og_berekend, m, s),
                   bg_berekend_untr = unscale(bg_berekend, m, s),
                   p02.5_untr = unscale(p02.5, m, s),
                   p97.5_untr = unscale(p97.5, m, s),
                   se_berekend_untr = ((p97.5_untr  - mean_untr )/1.96 - 
                                         (p02.5_untr  - mean_untr )/1.96)/2,
            )
        }
      resultlijst <- list( result_stat, 
                           result_fitted)
      names(resultlijst) <- c(resultname_stat, resultname_fitted)
      list2env(resultlijst, envir = .GlobalEnv)
      
      if (varname_mean %in% colnames(dagen_droog)) {
        dagen_droog <- dagen_droog %>% 
          dplyr::select(-!!varname_mean, -!!varname_sd, -!!varname_p025, -!!varname_p975) 
      }
      
      dagen_droog <- dagen_droog %>% 
         inner_join(result_fitted %>% 
                      dplyr::select(contains("fitted"), 1:3), 
                    by = c("meetpunt","simulatienr", "jaar")) 
    }
  }
  return(dagen_droog)
}

```

```{r abs-indic-model-function-final}
indic_abs_function <- function(modeldata, suffix= "", respons, percentile, indicatorname, standardised) {
  #De instelling van de prior heeft een doorslaggevend effect op de vorm van de trendlijn. 
  #Geven we het model de vrijheid om een trendlijn te bepalen dan voegen we weinig apriori-kennis toe aan het model
  #Voor de random-walk van de tweede orde doen we dat via de prior voor de precisie. Deze bevat twee elementen: de standaarddeviatie en een alfa. Het eerste element geeft aan in welke mate we denken/willen dat de rw2 mag fluctueren en en de alfa de zekerheid die we daarover hebben. Wil je een quasi rechte lijn, dan moeten beide parameters klein ingesteld worden. Laat je ze vrij, dan kan de trend een grillig patroon gaan vertonen.
  
  #voor de trendlijn zijn we vrij streng om een min of meer rechte, zacht glooiende, lijn te krijgen
  prec.prior <- list(theta = list(prior = "pc.prec", param = c(0.025, 0.001)))
  
  #ivm de variatie op de meetpunten brengen we niet veel voorkennis in het model, om deze zoveel mogelijk door het model te laten bepalen
  prec.prior.mp <- list(theta = list(prior = "pc.prec", param = c(0.025, 0.95)))# list(theta = list(prec = list(param = c(0.001, 0.001)))) 
  
  model <- as.formula(paste(respons, "~", "f(jaar, model =", "'rw2', scale.model = TRUE,
                          hyper = prec.prior)+ f(meetpunt, model = 'iid', hyper = prec.prior.mp)", sep = " "))   
       
  suffix <- ifelse(suffix == "", "", paste0("_", suffix))
  resultname_stat <- paste0("indic_abs_p", percentile, suffix, "_jaar_stat", if (standardised == TRUE) ("_std"))
  resultname_fitted <- paste0("indic_abs_p", percentile, suffix, "_fitted", if (standardised == TRUE) ("_std"))
  if (percentile == "01") {
    reeks <- c(1:20) #1 model wou maar niet convergeren
  } else {
    reeks <- c(1:20)    
  }  
  teller <- 0
  for (i in reeks) {
    #i = 16
    
    #samenstellen van een tweeledig dataframe. De eerste 34 rijen (#jaren) zijn leeg en dienen om de gemiddelde waarden en de bijhorende fouten te berekenen. Het tweede deel dient om het model mee te bouwen    
    mdata <- modeldata[modeldata$simulatienr == i,]
    jaren <- mdata %>% distinct(jaar) %>% mutate(simulatienr = i)
    mdata <- bind_rows(jaren, mdata)    

    print(i)    
    teller <- teller + 1
    I2 <- inla(model, 
                     control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE),
                     family = modelkeuze %>% filter(percentiel == percentile) %>% 
                              dplyr::pull(model), 
                     data = mdata
    )


    #linear_predictor : deze is niet teruggetransformeteerd. We zijn hier alleen geïnteresseerd in de rijen met lege responsen: hier krijg je dan per jaar een gemiddelde predictie én de se.
    result_stat_i <- I2$summary.linear.predictor %>% 
      slice(1:nrow(jaren)) %>% 
      bind_cols(jaren) %>% 
      mutate(intercept = I2$summary.fixed$mean) %>% 
      dplyr::select(-mode, -kld)    

        #gefitte waarden (deze zijn wel teruggetransformeteerd)    
    varname_mean <- paste0("p", percentile, "_mean", if (standardised == TRUE) ("_std"), "_fitted")
    varname_sd <- paste0("p", percentile, "_sd", if (standardised == TRUE) ("_std"), "_fitted")
    varname_p025 <- paste0("p", percentile, "_p02.5", if (standardised == TRUE) ("_std"), "_fitted")
    varname_p975 <- paste0("p", percentile, "_p97.5", if (standardised == TRUE) ("_std"), "_fitted")
    result_fitted_i <-  I2$summary.fitted.values %>% 
      rename(!!varname_mean := mean,
             !!varname_sd := sd,
             !!varname_p025 := '0.025quant',
             !!varname_p975 := '0.975quant')

    mdata <- bind_cols(mdata, result_fitted_i) %>% 
      slice(-(1:nrow(jaren))) #de regels met lege responsen hieruit verwijderen    
    
    if (standardised == TRUE) {
      varname_mean_backtransformed <- paste0(varname_mean, "_untr")
      varname_p025_backtransformed <- paste0(varname_p025, "_untr")
      varname_p975_backtransformed <- paste0(varname_p975, "_untr")
      result_fitted_i <- result_fitted_i %>% 
        mutate( !!varname_mean_backtransformed := unscale(result_fitted_i %>% 
                                                            dplyr::pull(!!varname_mean),m,s),
                !!varname_p025_backtransformed := unscale(result_fitted_i %>% 
                                                            dplyr::pull(!!varname_p025),m,s),
                !!varname_p975_backtransformed := unscale(result_fitted_i %>% 
                                                            dplyr::pull(!!varname_p975),m,s)    
        )
    }
    if (teller == 1) {
      result_stat <- result_stat_i
      result_fitted <- mdata
      
    } else {
      result_stat <- bind_rows(result_stat, 
                               result_stat_i)
      result_fitted <- bind_rows(result_fitted, mdata)    
    }
    
    if (teller == length(reeks)) {  
      result_stat <- result_stat %>% 
        rename( p02.5 = '0.025quant',
                p50 = '0.5quant',
                p97.5 = '0.975quant')
      
        if (standardised == TRUE) {
          result_stat <- result_stat %>% 
            mutate(mean_untr = unscale(mean, m, s),
                   og_berekend_untr = unscale(og_berekend, m, s),
                   bg_berekend_untr = unscale(bg_berekend, m, s),
                   p02.5_untr = unscale(p02.5, m, s),
                   p97.5_untr = unscale(p97.5, m, s),
                   se_berekend_untr = ((p97.5_untr  - mean_untr )/1.96 - 
                                         (p02.5_untr  - mean_untr )/1.96)/2,
            )
        }
      resultlijst <- list( result_stat, 
                           result_fitted)
      names(resultlijst) <- c(resultname_stat, resultname_fitted)
      list2env(resultlijst, envir = .GlobalEnv)
      
      if (varname_mean %in% colnames(dagen_droog)) {
        dagen_droog <- dagen_droog %>% 
          dplyr::select(-!!varname_mean, -!!varname_sd, -!!varname_p025, -!!varname_p975) 
      }
      
      dagen_droog <- dagen_droog %>% 
         inner_join(result_fitted %>% 
                      dplyr::select(contains("fitted"), 1:3), 
                    by = c("meetpunt","simulatienr", "jaar")) 
    }
  }
  return(dagen_droog)
}

```

```{r abs-indic-model-backup data}
dagen_droog_bu <- dagen_droog 
```

```{r abs-indic-model, include=FALSE}
#bij een eventuele herberekening moet de velden met de rekenresultaten eerst verwijderd worden
dagen_droog <- dagen_droog %>% 
  dplyr::select(-contains("fitted") )

modeldata <- dagen_droog


modelkeuze <- data.frame(percentiel = c("01", "05", "10", "30" ), model = c("zeroinflatednbinomial2", "zeroinflatednbinomial0", "zeroinflatednbinomial0", "nbinomial"))
modelkeuze$model <- as.character(modelkeuze$model)

#keuze van parameters
percentile <- "05"
indicatorname <- paste0("dag_onder_p",percentile)
indicatorname_inv <- paste0("dag_boven_p",percentile)
standardised <- FALSE
respons <- paste0(indicatorname, if (standardised == TRUE) ("_std"))


dagen_droog <- indic_abs_function(modeldata = modeldata, respons = respons, percentile = percentile, indicatorname = indicatorname, standardised = standardised)
```
```{r trend-data-vc, include=FALSE}

#bewaren resultaat
write_vc(dagen_droog, file.path("data", "result", "dagen_droog"), sorting = c("jaar", "meetpunt", "simulatienr"), strict = FALSE)

```

```{r trend-rubin}

#berekenen van indicator
indic_abs_gem <- dagen_droog %>% 
  group_by(jaar) %>% 
  summarise_at(vars(dag_onder_p01:dag_onder_p30), list(~mean(.), ~median(.))) %>% 
  ungroup


# rekening houden met multiple imputaties


droogte_trend_05 <- indic_abs_p05_jaar_stat %>% 
  group_by(jaar) %>% 
  summarise(gem_jaar_t = mean(mean),
            var_sim = sum(sd^2) / 20 + (1 + 1/20) * sum((mean - gem_jaar_t)^2)/(20 - 1),
            og_jaar_t = gem_jaar_t - 1.96 * sqrt(var_sim),
            bg_jaar_t = gem_jaar_t + 1.96 * sqrt(var_sim),
            gem_jaar = exp(gem_jaar_t),
            og_jaar = exp(og_jaar_t),
            bg_jaar = exp(bg_jaar_t)
  ) %>% 
  ungroup() %>% 
  inner_join(droogte_ind_j, by = "jaar")
```

Figuur \@ref(fig:trend-fitting-fig) geeft het resultaat van de modelbouw. 
De figuur toont de zowel de werkelijke waarden (punten) als de door het model geschatte waarden per meetpunt met hun betrouwbaarheidsinterval. 

```{r trend-fitting-fig-save, message=FALSE, warning=FALSE, include=FALSE}
fig <- plotfitting(indic_basis = dagen_droog, respons = "dag_onder_p05", gemid = "p05_mean_fitted", og = p05_p02.5_fitted, bg = p05_p97.5_fitted)
png(paste0(file.path("data","result", "figures","dagen_droog_p05"),"_tijdreeks",".png"))
fig
dev.off()

```

```{r trend-fitting-fig, fig.cap="gefitte waarden",  message=FALSE, warning=FALSE}
fig
```

Figuur \@ref(fig:trend-fig) geeft het finale resultaat: de droogte-indicatorwaarden en de trend met haar betrouwbaarheidsinterval. 
 
```{r trend-fig-save, fig.cap="trend", message=FALSE, warning=FALSE, include=FALSE}
#plot van de trend
gplot <- plottrend(droogte_trend_05,"droogte_ind_j", 18)
png(paste0(file.path("data","result", "figures","dagen_droog_p05"),"_trend",".png"))
gplot
dev.off()
```
 
```{r trend-fig, fig.cap="trend",  message=FALSE, warning=FALSE}
gplot
```


```{r trend-vc, include=FALSE}
#bewaren resultaten
write_vc(droogte_trend_05, file.path("data", "result", "droogte_trend_05"), sorting = c("jaar"), strict = FALSE)

write_vc(indic_abs_p05_jaar_stat, file.path("data", "result", "droogte_fitting_05"), sorting = c("jaar", "simulatienr"), strict = FALSE)
```


```{r trend-csv-voor-nara, include=FALSE}
#bewaren data voor figuur in nara
write_csv(droogte_trend_05 %>% dplyr::select(jaar, gem_jaar, og_jaar, bg_jaar, droogte_ind_j) %>% rename (`aantal dagen onder kritisch minimum`= droogte_ind_j), file.path("data", "result", "figuur_nara.csv"))
```

